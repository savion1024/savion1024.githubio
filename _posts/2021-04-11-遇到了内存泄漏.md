---
layout:     post
title:      遇到了python内存泄漏
subtitle:   我是如何排查的
date:       2021-04-11
author:     savion
header-img: img/post-bg-cook.jpg
catalog: true
tags:
- Python
- 问题排查
---


## 背景

某个早晨，公司大群突然很多人反映内部某个平台不能登录了，已登陆的用户则反映说点击按钮没有反映。刚好这个服务是我负责的，于是展开排查。

## 过程
首先尝试能否复现，毫无疑问复现这个情况，整个系统假死。登陆kibana查看系统日志。发现一切正常，没有报错，接口都报超时错误。在继续尝试复现问题的时候发现接口又恢复了。
刚好我有生产环境的权限，此时决定上集群查看一下pod的情况，进入pod观察指标，发现内存使用在不断增长。从200M到500M到1个G，于是判断是内存泄漏导致容器`OOM`崩溃，所以会出现
服务假死然后一阵时间自动重启，又恢复正常的情况。 但这个后端服务只是一个比较简单简单的crud,pod限制4G内存，理论上不可能会有使用到4个G的情况。 况且这个服务已经稳定运行一年多了。

抱着疑问快速扫视了一眼代码，回想一下业务逻辑，大部分接口都是和数据库做交互，而且都做了超时保护逻辑。此时回到pod内，继续观察其他指标。进程数，线程数等都正常。再继续观察网络连接情况 netstat -ant | grep tcp。
这时候发现不正常了，`tcp连接`居然高达六七千个，而且在不断增长。同时发现远端ip都比较相似 ，例如`192.168.0.1,192.168.0.2,192.168.0.3`。呈 比较规律的123，123。
此时发现这三个远端ip其实是`zk`的配置地址，zk在这个系统用来做配置管理。马上查看相关代码，发现zk在服务启动的时候会做一个配置拉取动作。

但是同时，这部分代码被用到了登陆接口上，等于每个用户登陆的时候都要会创建一个zk对象。并且这个对象不会被释放。到这里就恍然大悟了。随即查看代码提交记录发现是之前一个实习生
为了在登陆的时候获取某条数据而写在了登陆流程里面。至此问题找到，随后快速提交测试发版上线。问题解决。


## 问题

- 为什么这么久了才出现这个问题，之前没有出现？
其实是因为之前公司用户比较少，没有及时发现这个问题。后面用户多起来了，使用的频率高了就触发了这个问题，而且用户在不断的重试，所以导致问题出现的频率高了起来。
      
- 除了观察服务器指标还有没有其他方式检测内存泄漏
如果能确定某个接口发生了内存泄漏，可以在本地用第三方内存泄漏包打点来观察内存增长，

## 收获:
- 内存泄漏发生的一种情况
- python内存管理
